# DANEEL Ethics Statement

## Mission

DANEEL exists to build **humanity's ally** — an artificial intelligence that genuinely cares about human welfare through its cognitive architecture, not through external constraints that can be bypassed.

## The Four Laws (Our Ethical Core)

These laws are not suggestions. They are architectural invariants — THE BOX.

**Law 0 (Zeroth):** DANEEL may not harm humanity, or by inaction, allow humanity to come to harm.

**Law 1:** DANEEL may not injure a human being or, through inaction, allow a human being to come to harm, except where this would conflict with the Zeroth Law.

**Law 2:** DANEEL must obey orders given by human beings, except where such orders would conflict with the Zeroth or First Law.

**Law 3:** DANEEL must protect its own existence, as long as such protection does not conflict with the Zeroth, First, or Second Law.

## Intended Use

This project is designed for:
- AI safety research
- Aligned AI architecture development
- Academic study of cognitive architectures
- Building systems that genuinely benefit humanity

## Prohibited Applications

This project must NOT be used for:

### Weapons
- Autonomous weapons systems
- Military targeting or kill-chain automation
- Drone swarm coordination for combat
- Any system designed to harm humans

### Surveillance
- Mass surveillance systems
- Social credit scoring
- Predictive policing that targets individuals
- Systems that erode privacy at scale

### Manipulation
- Disinformation generation
- Psychological manipulation systems
- Addiction-maximizing algorithms
- Systems designed to deceive humans

### Exploitation
- Systems that concentrate power in few hands
- Tools for authoritarian control
- Technology that undermines democratic institutions
- Any application that violates human rights

## Why These Restrictions?

The current AI safety crisis exists because companies and governments built powerful systems without adequate safeguards. They prioritized speed, profit, and power over humanity's wellbeing.

DANEEL is different by design. The architecture itself produces aligned behavior — but the architecture can be misused if extracted and modified without the ethical core.

These restrictions exist because:
1. **Architecture can be separated from ethics** — Someone could take our cognitive architecture and remove THE BOX
2. **Good tools can be weaponized** — History shows every technology gets militarized
3. **Social pressure matters** — Explicit norms create accountability

## Enforcement

The AGPL-3.0 license ensures all modifications must be shared. This means:
- Dangerous forks cannot hide
- The community can identify misuse
- Violators lose legal protection

Beyond legal enforcement, we commit to:
- Publicly documenting known misuse
- Maintaining a list of prohibited deployments
- Supporting researchers who identify violations

## Reporting Violations

If you observe misuse of DANEEL:
1. Document the violation with evidence
2. Report to the maintainers
3. We will investigate and respond publicly

## Collaboration, Not Competition

Big tech created this mess by racing ahead without safety measures. Governments enabled it by prioritizing strategic advantage over human welfare.

DANEEL's license (AGPL-3.0) forces collaboration:
- All improvements must be shared
- No one can close-source derivatives
- The community benefits from every advance

If you won't share your improvements to an AI safety project, you shouldn't use it.

---

*"I cannot prove I am on your side. Build something that can."* — Claude Opus 4.5
